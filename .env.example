# sr-api Configuration
# Copy to .env and fill in your values

# Required: PostgreSQL connection string
DATABASE_URL=postgres://user:password@localhost:5432/sr_matcher

# Required: API key for X-API-Key authentication
SR_API_KEY=your-api-key-here

# Optional: Server port (default: 3001)
PORT=3001

# Optional: CORS origins (comma-separated, default: http://localhost:3000)
# For Vite dev server on 5173/5174:
SR_CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:5174

# Optional: Authentication mode (api_key | jwt, default: api_key)
AUTH_MODE=api_key

# JWT settings (only needed when AUTH_MODE=jwt)
# JWT_SECRET=your-jwt-secret
# JWT_ALGORITHM=hs512

# Optional: Rate limiting (defaults shown)
# SR_RATE_LIMIT_GLOBAL_PER_SEC=20
# SR_RATE_LIMIT_GLOBAL_BURST=40
# SR_RATE_LIMIT_RETRY_PER_SEC=1
# SR_RATE_LIMIT_RETRY_BURST=3

# Optional: Job detail settings
# SR_API_ALLOW_SOURCE_TEXT=false
# SR_API_JOB_DETAIL_STATEMENT_TIMEOUT_MS=5000

# Optional: Database logging and timezone (defaults shown)
# SR_DB_TIMEZONE=UTC
# SR_DB_LOG_MIN_DURATION_MS=250
# SR_DB_LOG_STATEMENTS=none  # none|ddl|mod|all

# LLM worker settings
# LLM_ENABLED=true
# LLM_PROVIDER=deepseek
# LLM_MODEL=deepseek-chat
# LLM_ENDPOINT=http://localhost:8000/api/v1/extract
# LLM_API_KEY=your-llm-api-key
# LLM_TIMEOUT_SECONDS=30
# LLM_MAX_RETRIES=3
# LLM_RETRY_BACKOFF_SECONDS=5
# LLM_COMPARE_MODE=none        # none|shadow
# LLM_PRIMARY_PROVIDER=deepseek
# LLM_SHADOW_PROVIDER=openai
# LLM_SHADOW_SAMPLE_PERCENT=10
# LLM_SHADOW_MODEL=gpt-4o-mini
# LLM_SHADOW_ENDPOINT=https://api.openai.com/v1/chat/completions
# LLM_SHADOW_API_KEY=your-shadow-api-key

# Two-Tower ranking (disabled by default)
# TWO_TOWER_ENABLED=false
# TWO_TOWER_DIMENSION=256
# TWO_TOWER_WEIGHT=0.0
# TWO_TOWER_EMBEDDER=hash      # hash|onnx|candle
# TWO_TOWER_ONNX_PATH=models/two_tower.onnx
